---
layout: essay
type: essay
title: "Is Artificial Intelligence the 'Pandora's Box' of the Digital Age?"
date: 2023-08-07
published: true
labels:
  - Artificial Intelligence
---

![AI with Pandora's Box](https://github.com/user-attachments/assets/c1fd9f9c-c4c1-4abb-8493-d2a41d27372b)
<br>
(*image source: cxodigitalpulse.com*)



## From Mythical to Reality

Would you ever expect a newborn child to beat a grandmaster at a game of chess (Hunt)? Now, let’s consider the very likely possibility of Artificial Intelligence (AI) becoming a grandmaster, or superintelligence, as we continue to grasp information approximately one billion times slower (Mahendra). The speed in which AI can receive an unbelievable amount of data, then master a given subject can essentially create a “Pandora’s Box” of the digital age. However, this is not a mythological fantasy, this could well be our reality. Our world has already experienced the aftereffect of AI replacing humans in the workforce, which will ultimately affect our economy, if the integration is not limited. Although, policies may lessen the impact on our economy, regulations and policies will not last in controlling autonomous AI in other aspects. Our reality is existentially threatened by the continued autonomous AI development, or even the release of existing AI (e.g., chemical and security threats), which has been deemed by their own creators as potentially lethal. Efforts need to be refocused on mitigations of the existential threats.

## The Industrial Revolution to The Digital Revolution

Since the world transitioned from the Industrial Revolution to the digital revolution, approximately in 1980, the Gini coefficient1 formula has illustrated the increasing economic gap. Many believe the “factory model school education” that shaped the American school system was developed to create obedient factory workers, benefited the industrial revolution (Watters). Will there be an increase in education of the digital changes after implementing AI, that is accessible (free) to the public that could help to slow the wage inequality? Altering or adding to our education is only part of the government’s responsibility to initiating mitigating measures.

If additional measures, like inaugurating policies, are not in place, the growing acceptance of AI will worsen already-existing social inequalities or even the imbalance of social control. Although possible, I have not found any evidence suggesting such measures are even being discussed. Sadly, even at the worst possible outcome concerning the economic issue is not the more substantially greater issue among us, the possible threat to the mere existence of mankind is.

## Let's not ignore the positive contributions.

Before I further explain why I am opposed to supporting the continuation in the development of AI, or more specifically, autonomous AI, I understand that there can be and are positives to the advancement of AI. For instance, AI has already enhanced and accelerated the process for pharmaceutical cures for illnesses. In fact, Japanese pharmaceutical firm Sumitomo Dainippon Pharma has initiated a trial on a new molecule invented by AI, known as DSP-1181, which aids in the cure for obsessive compulsive disorder (OCD). The molecule is already in its trial release in Japan. This is considerably beneficial, as patients diagnosed with OCD account for over one million of Japan’ population. I understand the hope in AI creating a cure for more fatal disorders and conditions, like Alzheimer’s or cancers.

## Are the positives enough?

It is not just in the medical world. Nations like the U.S. and Russia have already implemented AI involvement through autonomous fighter jets and drones on the battlefield. “AI-enabled drone swarm that operates faster than the defense can respond could hold its rivals hostage during crises…” (Benjamin 539). Potentially, the advantage of AI support, like sending AI robots in to conduct a reconnaissance on a village instead of Soldiers or Marines, may lead to less human sacrifice on the frontline. With the positives, there are still too many negatives countering the benefits. The further we push for AI involvement on the battlefield, the more foreign adversaries will feel the need to increase their advancements, in the same way that motivated nations around the world to develop nuclear bombs.

Medicine and war may be the very reason why AI advancement is necessary, but they are also examples of why it is imperative that we stop. AI has created molecules to heal, but as Sean Ekins, CEO of Collaborations Pharmaceuticals, and Fabio Urbina, Collaborations Pharmaceuticals, proved that AI can also create molecules to kill. Ekins and Urbina illustrated the dangers by altering a single binary code and ultimately prompting the AI system to develop the most toxic molecule known to mankind (Netflix 25:05¬-25:21). The possibility of the release of these toxins will easily become the most catastrophic outcome that our world is not prepared to battle. The release of these toxic molecules could very well be the beginning of the existential threat, or the opening of Pandora’s box. 

We are currently the society that had survived the international pandemic, COVID-19. Although, there may have been speculation on how fast the cure or vaccine was created for the pandemic, our society still had to endure years of its effects on our world. After many precautions and safety nets put in place, we might be more well prepared for a pandemic, but are we willing to risk an outbreak again? The release of such toxic chemicals may repeat the horrors COVID-19 brought to our lives: increasing unbelievable death tolls, closing of life-invested businesses, and ceasing any opportunity for those abroad from returning home to their loved ones. In comparison, a chemical outbreak may be more alarming than what the world endured during the COVID-19 pandemic. 

In some ways, modern technology promises to change the nature of military power, but this may cause an inhumane consequence. Specifically, autonomous AI machines that are able to administer itself and dictate its actions without human intervention. In 2015, “Google’s automated image recognition system in a photo application misidentiﬁed African Americans, erroneously creating an album titled ‘Gorillas’” (Schupak). If AI is not able to recognize the difference between people and animals, or adopt a prejudice bias with just photos, should we trust it to master identifying people under suspicion? 

The inaccuracy in AI’s scanning capabilities may lead to misidentification of innocent civilians mistaken for an enemy target. If that does not sound bad enough, consider the fact that AI has erroneously identified individuals, then consider a program with a similar concept in an assassination attempt. Remember, unlike the racist categorizing of Google’s automated image recognition system, we cannot rescind the horrid mistake of an innocent life taken by a simple x.com (formerly known as twitter) post. 

We cannot trust autonomous AI robots to be able to accurately and without bias, follow the rules of engagement (ROE) downrange. These robots lack the humanistic qualities of emotions like fear or compassion in following its commands. These are the very qualities that aid in a Soldier’s judgement. Even with Soldiers on the battlefield, there is still a realization that the “battlefield” is still the home of many innocent civilians. A home filled with hospitals, schools, and churches. 

These killing machines will only know what commands are given to follow. Ergo, what is stopping an autonomous AI programmed killing machine from following a command ‘to engage a target’ from following a target into a hospital or school filled with innocent civilians? In the same context, an autonomous AI programmed killer may not be able to follow the Geneva Conventions codes, which are treaties specifically addressing safety concerns of innocent civilians, the sick and injured, or medical personnel. In order to abide by the Geneva Conventions, AI would have to identify each person within its scope, then judge its surrounding to incisively decide to complete its mission or disengage. Without the humanistic qualities, this is an impossible judgement call for a robot.
 
If the world continues to move forward with autonomous AI implementation on the battlefield, human intervention will be irrelevant once it has a mind of its own. Once AI adapts to its own will, stopping the most intelligent weapons of mass destruction from becoming uncontrollable killer machines, will be an impossible task in itself. AI will eventually operate without human intervention as it heuristically adapts. Just as AI created the most toxic molecule while both scientists, Ekins, and Urbina, were sitting at home and unaware of its true capabilities. Once the most intelligent creation known to mankind, becomes the deadliest creation known to mankind, it will be the end of human control. Even worse, it may be the end to the greater population of human life.

Let’s review the point that we can add policies and there’s a way to regulate it to protect mankind. This would only work if nations agreed upon policies that will prioritize the well-being of mankind. Defense Secretary Dr. Mark T. Esper mentions how Russian President Vladimir Putin and Chinese Communist Party plan to rule the world with AI (Garamon). Their actions should be a warning to the remaining nations. We need to focus attention towards lessening the severity of their strengths in the AI aspect of war.  

Additionally, AI has even been compared to nuclear weapons. Following the development of nuclear weapons, the same scientists who invented the nuclear weapons led the way in imposing restrictions. Some may argue that this may be the same outcome with superintelligence. However, nuclear warfare is not autonomous. Regulations and policies may not be enough to control autonomous AI. 

## Closing thoughts

It may no longer be a choice for us to regulate it, but the best outcome would be to not advance any further. With AI already receiving an unbelievable amount of data to heuristically adapt in a kill zone or create deadly chemicals, we are not far from the release of a catastrophic chemical and security threat. I am afraid that it may be too late. I believe that we are playing with the “Pandora’s Box” of the digital age, in real life. With the existence of the most toxic molecules and autonomous killer robots, Pandora’s box may have already opened. Therefore, by refocusing our efforts towards plans of mitigating any of the possible existential threats, we will place the existence of our world in a more likely outcome of survival. 

Work Cited

Hunt, Tamlyn. “Here’s Why AI May Be Extremely Dangerous—Whether It’s Conscious       or Not.” Scientific American, 25 May 2023, www.scientificamerican.com/article/heres-why-ai-may-be-extremely-dangerous-whether-its-conscious-or-not.

Mahendra, Sanksshep. “Are Humans Smarter Than AI?” Artificial Intelligence +, June 2023, www.aiplusinfo.com/blog/are-humans-smarter-than-ai/#:~:text=AI%20can%20process%20information%20billions,the%20synergy%20of%20biological%20intelligence.

Wakefield, By Jane. “Artificial Intelligence-created Medicine to Be Used on Humans for First Time.” BBC News, 30 Jan. 2020, www.bbc.com/news/technology-51315462.

Garamon, Jim. “Esper Says Artificial Intelligence Will Change the Battlefield.” U.S. Department of Defense, www.defense.gov/News/News-Stories/Article/Article/2340972/esper-says-artificial-intelligence-will-change-the-battlefield.
